---
title: Ceph (Mimic) を Ubuntu 18.04 に入れた時の構築メモ
permalink: /p/584ab1d017984612bdd88366f32c7aee
tags: []
date: 2018-08-09 03:00:00
updated: 2021-07-29 02:24:28
---

## 変更履歴

- 20180818 ファイアウォール設定に不足があったので修正

## 環境

- Hyper-V 上の Ubuntu 18.04LTS 3 台の構成
- ceph\* はパブリック(192.168.10.0/24) と ceph 専用ネットワーク (172.16.10.0/24) の両方に接続
- cephadmin = (admin, mon) publicip=192.168.10.201\~200 privateip=172.16.0.200
- cephosd1~~2 = (mon, osd) publicip=192.168.10.201~~202 privateip=172.16.0.201\~202
- cephadmin は adminnode を兼ねています。

## 目的

- S3 互換ストレージサービスを動かす

## 基本的な手順

公式の Getting Started に従う

<a href="http://docs.ceph.com/docs/master/start/quick-ceph-deploy/"><http://docs.ceph.com/docs/master/start/quick-ceph-deploy/>

## しくじりポイント

なぜこの項目が作業手順より先にあるのかというと･･･

クラスタものなのでしくじったら基本的にやり直しした方がよろしいと思われる為です。

しくじったら以下のコマンドで全部やりなおし。VM を使っているならチェックポイントやスナップショットも使えますが、一度全部通るまでは以下のコマンドでやり直す方が早いです。

```
`ceph-deploy purge cephosd1 cephosd2 cephosd3
ceph-deploy purgedata cephosd1 cephosd2 cephosd3
ceph-deploy forgetkeys
rm ceph.*
```

### OSD は 3 台ないと上手くいかない

Luminous 以前は上手くいったという Qiita 記事等が見つかるのですが、Mimic では 3 台ないと

上手く行かないようです。

### 先に ceph というユーザーを作ってはいけない

作ってしまうと、 `ceph-deploy install cephadmin cephosd1 cephosd2` がコケる

自動的に ceph ユーザーが作られるので作業用のユーザーは別のユーザーである必要があります。

root でも良いのかも。

### クラスタの全てのホストには python2 コマンドが必要である

ceph-deploy を入れるホストは、依存性で自動的にインストールされますが、その他のホストには手動でインストールが必要そうです。

インストールしていないと、 `ceph install` で、 `bash: python2: command not found` と言われてコケます。

python3 はともかく python2 ってなんじゃい？と思いますが、python2.7 を入れると入ります。

```
`apt install python-minimal   #python2.7-minimal ではありません！！
```

### sudo が必要な状態だと失敗する？

```
`[ceph_deploy.install][DEBUG ] Detecting platform for host cephosd1 ...
[cephosd1][DEBUG ] connection detected need for sudo
sudo: no tty present and no askpass program specified
[ceph_deploy][ERROR ] RuntimeError: connecting to host: cephosd1 resulted in errors: IOError cannot send (already closed?)
```

/etc/sudoer を変更して（visudo 使っておきました）パスワード不要にしても同じ症状。

わけがわからない･･

#### 【暫定】とりあえず、root から直接行くようにすることで対応

cephadmin で `sudo su -` してその状態で、cephosd1, cephosd2 に ssh 鍵認証が通るように設定。

（要するに、 root\@cephadmin で `ssh-keygen` して、 id_rsa.pub の内容を cephosd1,2 の authorized_keys に追加）

### hosts で名前解決を行うなら、記述するのは public ip

cephadmin -> cephosd\* は名前でアクセスできないといけないが、名前解決といえば

/etc/hosts ファイルを使うのが一番簡単。しかし、ここに記述するのは public な IP アドレスでなければいけない。今回の例なら _172.16.0.21 と書くのは NG_ で _192.168.10.201 が正解_

（これだけで 5 回はしくじりました）

参考資料：

<a href="http://docs.ceph.com/docs/master/rados/configuration/network-config-ref/"><http://docs.ceph.com/docs/master/rados/configuration/network-config-ref/>

```
`192.168.10.200   cephadmin
192.168.10.201   cephosd1
192.168.10.202   cephosd2
```

## 実作業ログ

以下は実際の作業時の手順です。

- (事前に、ssh, ntp は構成済み)
- ceph-deploy は既に構成済み <a href="http://docs.ceph.com/docs/mimic/start/quick-start-preflight/"><http://docs.ceph.com/docs/mimic/start/quick-start-preflight/>

### 最初の mon を構成

```
`mkdir ceph-cluster
cd ceph-cluster
ceph-deploy new cephosd1 cephosd2 cephadmin
```

```
`vi ceph.conf
// 以下二行追加
# osd pool default size = 2  入れても効果がないように見えます
public network = 192.168.10.20/24
```

### ceph インストール

```
`ceph-deploy install cephosd1 cephosd2 cephadmin
# aptを実行しているようで結構時間がかかる
```

### MON 初期化？

しくじりがあれば大抵ここでコケます。祈りながら実行します。

```
`ceph-deploy mon create-initial
```

### 設定ファイルと鍵をコピー

```
`ceph-deploy admin cephosd1 cephosd2 cephadmin
```

### OSD を作成

ミスると、ゴミ OSD が生成されますが、後で消せるのでとりあえず続行しましょう。

```
`ceph-deploy osd create --data /dev/sdb cephadmin
ceph-deploy osd create --data /dev/sdb cephosd1
ceph-deploy osd create --data /dev/sdb cephosd2
```

地味なハマりポイント、指定するのはディスク全体。パーティション作ってたりすると失敗する。

`stderr: Device /dev/sdb excluded by a filter.` と出てしまったら以下のコマンドを実行後、osd create を再実行。これはリモートでできない（？）みたいなので必要なら SSH する。

`ceph-volume lvm zap /dev/sdb` これをしたときに resource busy となった場合は、既に LVM にディスクが掴まれているので、 `/bin/dd if=/dev/zero of=/dev/sdb bs=1M count=10` してから再起動すれば OK。

### メタデータサーバー作成

```
`ceph-deploy mds create cephadmin
```

### S3 互換ストレージ <=> RADOS ゲートウェイ

単語集

<a href="http://docs.ceph.com/docs/master/glossary/#term-ceph-object-gateway"><http://docs.ceph.com/docs/master/glossary/#term-ceph-object-gateway>

```
`ceph-deploy rgw create cephadmin
```

試しに `curl http://192.168.10.200:7480/` すると何かでるはずです。

### Manager 作成

これが終わると、ダッシュボードが使えるようになります。

使えるようになりますが、 <a href="https://192.168.10.200:8443/"><https://192.168.10.200:8443/> です。443 じゃないです

```
`apt install python-routes    # 入れておかないとコケるらしい
ceph-deploy mgr create cephadmin
ceph-deploy --overwrite-conf mgr create cephadmin

ceph dashboard create-self-signed-cert
ceph dashboard set-login-credentials <username> <password>
radosgw-admin user create --uid=<username> --display-name=<displayname> --system
# ここでJSON形式でユーザー情報が出るのでコピっておく
ceph dashboard set-rgw-api-access-key <JSONの access key>
eph dashboard set-rgw-api-secret-key <JSONの secret key>

# ダッシュボード再起動
ceph mgr module disable dashboard
ceph mgr module enable dashboard
```

<img src="https://qiita-image-store.s3.amazonaws.com/0/2454/0e997151-4200-53ab-eaa8-a0ea95602f3e.png" alt="Greenshot 2018-08-10 19.14.22.png" loading="lazy">

### ゴミ OSD の削除

OSD の作成で失敗していると、ダッシュボードに無名で、 down, out 状態な OSD が表示されます。

残っていても恐らく問題はないのですが気持ち悪いので削除します。

ダッシュボード上で ID（数字） を確認してから実行して下さい。

```
`ceph osd out <id>
ceph osd purge <id> --yes-i-really-mean-it
```

## ここまでで出来るようになったこと

- S3 互換のストレージが使える <a href="http://192.168.10.200:7443/"><http://192.168.10.200:7443/>
- ダッシュボードが使える <a href="https://192.168.10.200:8443/"><https://192.168.10.200:8443/>

ダッシュボードから S3 互換ストレージのバケットを作れますし、ユーザー管理もできるようになりました。

## 追記　ファイアウォールの設定

実際に使った設定を少し改変しています。

```
`# web画面（アクセス元絞った方がよいかも）
ufw allow 8443

# ssh
ufw allow ssh

# MON(フロント）
ufw allow from 192.168.10.0/24 to any port 6789

# MON(バック。不要なはずなんだけど開けないと上手くいかなかった）, OSD
ufw allow from 172.16.0.0/24 to any port 6800:7300 proto tcp
ufw allow from 172.16.0.0/24 to any port 6789

# MDS and MGR （フロントだけで良いはずだけど、結局OSDと同じポート範囲）
ufw allow from 192.168.10.200 to any port 6800:7300 proto tcp
ufw allow from 192.168.10.201 to any port 6800:7300 proto tcp
ufw allow from 192.168.10.202 to any port 6800:7300 proto tcp

# 20180818 追記
# cephfs を使用すると、各OSDに直接アクセスに行くので同一ネットワーク内から
# osdへのアクセスを許可するようにルール追加
ufw allow from 192.168.10.0/24 to any port 6800:7300 proto tcp

```
